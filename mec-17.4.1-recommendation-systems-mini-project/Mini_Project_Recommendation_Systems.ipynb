{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mini_Project_Recommendation_Systems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkqlbEEvsHuw"
      },
      "source": [
        "# Recommendation Systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siTq9DI-Fsy_",
        "outputId": "dade1ffc-e961-432a-91e1-d44e8c49cd3f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXCjew2ItepU"
      },
      "source": [
        "Companies like Amazon(books, items), Netflix(movies), Google(News,Search), and Pandora/Spotify(music) leverage recommendation systems to help users discover new and relevant items (products, videos, jobs, music), creating a delightful user experience while driving incremental revenue. \n",
        "\n",
        "The need to build robust recommendation systems is extremely important given the huge demand for personalized content of modern consumers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lc420j2uhwZ"
      },
      "source": [
        "In this assignment, you will be applying your learning of recommendation systems in this Unit towards building the following four different types of recommendation systems:\n",
        "\n",
        "1.   Global Recommendation Systems (Statistical)   \n",
        "2.   Content-based Recommendation Systems\n",
        "3.   Collaborative Filtering (User-Item) Recommendation Systems\n",
        "4.   Hybrid Recommendation Systems\n",
        "\n",
        "The focus of the mini-project here would be to build a movie recommendation system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3nuM_Kv17_"
      },
      "source": [
        "## 1. Dataset Acquisition\n",
        "\n",
        "Following are the key descriptions of the datasets you will be using. The data used here has been compiled from various movie datasets like Netflix and IMDb.\n",
        "\n",
        "1. __Filename: `movie_titles.csv`:__\n",
        "\n",
        "  - __`MovieID`__: MovieID does not correspond to actual Netflix movie ids or IMDB movie ids\n",
        "  - __`YearOfRelease`__: YearOfRelease can range from 1890 to 2005 and may correspond to the release of corresponding DVD, not necessarily its theaterical release\n",
        "  - __`Title`__: Title is the Netflix movie title and may not correspond to titles used on other sites. Titles are in English\n",
        "\n",
        "\n",
        "2. __Combined User-Ratings Dataset Description - `combined_data.csv`:__\n",
        "\n",
        "  - The first line of the contains the movie id followed by a colon.    \n",
        "  - Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n",
        "\n",
        "    - MovieIDs range from 1 to 17770 sequentially.\n",
        "    - CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users. \n",
        "    - Ratings are on a five star (integral) scale from 1 to 5.\n",
        "    - Dates have the format YYYY-MM-DD.\n",
        "\n",
        "\n",
        "3. __Filename: `movies_metadata.csv`__\n",
        "\n",
        "The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaic3a2Cw0T5"
      },
      "source": [
        "## 2: Import Necessary Dependencies\n",
        "\n",
        "We will be leveraging __`keras`__ on top of __`tensorflow`__ for building some of the collaborative filtering and hybrid models. There are compatibility issues with handling sparse layers with dense layers till now in TensorFlow 2 hence we are leveraging native Keras but in the long run once this issue is resolved we can leverage __`tf.keras`__ with minimal code updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX9t8rYaxVGh"
      },
      "source": [
        "# filter out unncessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGWCPwAiP7vv"
      },
      "source": [
        "# To store\\load the data\n",
        "import pandas as pd\n",
        "\n",
        "# To do linear algebra\n",
        "import numpy as np\n",
        "\n",
        "# To create plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# To compute similarities between vectors\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# data load progress bars\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# To create deep learning models\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
        "from tensorflow.keras.losses import MSE\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# To stack sparse matrices\n",
        "from scipy.sparse import vstack"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whZc1FgzyPyY"
      },
      "source": [
        "# remove unnecessary TF logs\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce2tjPHPzWFd",
        "outputId": "4d3c9d09-bf2f-4ac6-f09b-915ccfc817f8"
      },
      "source": [
        "# check keras and TF version used\n",
        "print('TF Version:', tf.__version__)\n",
        "print('Keras Version:', keras.__version__)\n",
        "# TF Version: 1.15.0\n",
        "# Keras Version: 2.2.5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version: 2.6.0\n",
            "Keras Version: 2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXXYudDD0Coy"
      },
      "source": [
        "Let's start loading data that will be used for building the recommendation systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FJZmUvExOYt"
      },
      "source": [
        "# 3. Load Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnAU78S7xz-H"
      },
      "source": [
        "## 3.1: Load Movie Metadata Datasets\n",
        "\n",
        "First, we will load the movie_titles.csv data from the Netflix prize data source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "tgD9whbBfcWW",
        "outputId": "d2b9599d-4f5f-4749-fc59-86ff119ad418"
      },
      "source": [
        "# Load data for all movies\n",
        "movie_titles = pd.read_csv('/content/drive/MyDrive/UCSD_MLE/Projects/mec-17.4.1-recommendation-systems-mini-project/data/movie_titles.csv', \n",
        "                           encoding = 'ISO-8859-1', \n",
        "                           header = None, \n",
        "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
        "\n",
        "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
        "movie_titles.sample(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Movie-Titles:\t(17770, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>Girls Can't Swim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11658</th>\n",
              "      <td>2004.0</td>\n",
              "      <td>Wicker Park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10951</th>\n",
              "      <td>1961.0</td>\n",
              "      <td>Judgment at Nuremberg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>1983.0</td>\n",
              "      <td>Krull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>1996.0</td>\n",
              "      <td>Emma (Miniseries)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Year                   Name\n",
              "Id                                  \n",
              "1469   2000.0       Girls Can't Swim\n",
              "11658  2004.0            Wicker Park\n",
              "10951  1961.0  Judgment at Nuremberg\n",
              "1104   1983.0                  Krull\n",
              "456    1996.0      Emma (Miniseries)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYafEzcYxa09"
      },
      "source": [
        "There are approximately 18000 movies in the ratings dataset and the metadata information includes the year of release and movie title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE4QaObcyAup"
      },
      "source": [
        "Next, we will load the movie_metadata.csv from The movies dataset source. This is to get the metadata information like description etc. related to each movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "WWig4ePBqGSD",
        "outputId": "37bbc5f3-7baf-4781-b579-ab2d47a3c59f"
      },
      "source": [
        "# Load a movie metadata dataset\n",
        "movie_metadata = (pd.read_csv('/content/drive/MyDrive/UCSD_MLE/Projects/mec-17.4.1-recommendation-systems-mini-project/data/movies_metadata.csv', \n",
        "                              low_memory=False)[['original_title', 'overview', 'vote_count']]\n",
        "                    .set_index('original_title')\n",
        "                    .dropna())\n",
        "\n",
        "# Remove the long tail of rarly rated moves\n",
        "movie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n",
        "\n",
        "print('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\n",
        "movie_metadata.sample(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Movie-Metadata:\t(21604, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>original_title</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Now You See Me</th>\n",
              "      <td>An FBI agent and an Interpol detective track a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Other Sister</th>\n",
              "      <td>A mentally challenged girl proves herself to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Toy Soldiers</th>\n",
              "      <td>After federal agents arrest a drug czar and pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hoop Dreams</th>\n",
              "      <td>This documentary follows two inner-city Chicag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>God Bless Ozzy Osbourne</th>\n",
              "      <td>Ozzy Osbourne's four decade track record as a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  overview\n",
              "original_title                                                            \n",
              "Now You See Me           An FBI agent and an Interpol detective track a...\n",
              "The Other Sister         A mentally challenged girl proves herself to b...\n",
              "Toy Soldiers             After federal agents arrest a drug czar and pu...\n",
              "Hoop Dreams              This documentary follows two inner-city Chicag...\n",
              "God Bless Ozzy Osbourne  Ozzy Osbourne's four decade track record as a ..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dElmRUSWyYoh"
      },
      "source": [
        "Around 21,000 entries in the movies metadata dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ3cHW1eyhwR"
      },
      "source": [
        "## 3.2: Load User-Movie-Rating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "4s_qbrIhqW31",
        "outputId": "57a08a8a-9e20-44b3-a056-aa5275bb4d56"
      },
      "source": [
        "# Load single data-file\n",
        "df_raw = pd.read_csv('/content/drive/MyDrive/UCSD_MLE/Projects/mec-17.4.1-recommendation-systems-mini-project/data/combined_data.csv', \n",
        "                     header=None, \n",
        "                     names=['User', 'Rating', 'Date'], \n",
        "                     usecols=[0, 1, 2])\n",
        "\n",
        "# Find empty rows to slice dataframe for each movie\n",
        "tmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\n",
        "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
        "\n",
        "# Shift the movie_indices by one to get start and endpoints of all movies\n",
        "shifted_movie_indices = deque(movie_indices)\n",
        "shifted_movie_indices.rotate(-1)\n",
        "\n",
        "# Gather all dataframes\n",
        "user_data = []\n",
        "\n",
        "# Iterate over all movies\n",
        "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
        "    \n",
        "    # Check if it is the last movie in the file\n",
        "    if df_id_1<df_id_2:\n",
        "        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
        "    else:\n",
        "        tmp_df = df_raw.loc[df_id_1+1:].copy()\n",
        "        \n",
        "    # Create movie_id column\n",
        "    tmp_df['Movie'] = movie_id\n",
        "    \n",
        "    # Append dataframe to list\n",
        "    user_data.append(tmp_df)\n",
        "\n",
        "# Combine all dataframes\n",
        "df = pd.concat(user_data)\n",
        "del user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
        "print('Shape User-Ratings:\\t{}'.format(df.shape))\n",
        "df.sample(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape User-Ratings:\t(24053764, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "      <th>Movie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21507136</th>\n",
              "      <td>1458266</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2004-08-16</td>\n",
              "      <td>4043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1908483</th>\n",
              "      <td>936387</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2004-07-29</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6797180</th>\n",
              "      <td>1729260</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2005-10-17</td>\n",
              "      <td>1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12920211</th>\n",
              "      <td>1253376</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2005-01-23</td>\n",
              "      <td>2457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23928275</th>\n",
              "      <td>147778</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2004-08-16</td>\n",
              "      <td>4472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21232039</th>\n",
              "      <td>1720072</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2005-01-02</td>\n",
              "      <td>3962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15871407</th>\n",
              "      <td>2507537</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2005-10-03</td>\n",
              "      <td>3090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4686539</th>\n",
              "      <td>2260286</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2004-09-22</td>\n",
              "      <td>919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6132108</th>\n",
              "      <td>470468</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2003-09-28</td>\n",
              "      <td>1202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3775546</th>\n",
              "      <td>1779860</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2005-05-06</td>\n",
              "      <td>720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             User  Rating        Date  Movie\n",
              "21507136  1458266     5.0  2004-08-16   4043\n",
              "1908483    936387     4.0  2004-07-29    357\n",
              "6797180   1729260     3.0  2005-10-17   1324\n",
              "12920211  1253376     3.0  2005-01-23   2457\n",
              "23928275   147778     3.0  2004-08-16   4472\n",
              "21232039  1720072     5.0  2005-01-02   3962\n",
              "15871407  2507537     3.0  2005-10-03   3090\n",
              "4686539   2260286     3.0  2004-09-22    919\n",
              "6132108    470468     3.0  2003-09-28   1202\n",
              "3775546   1779860     4.0  2005-05-06    720"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg90OAW_zUwL"
      },
      "source": [
        "There are about 24 Million+ different rating records!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKIrEduYz6gh"
      },
      "source": [
        "We have taken the data required for building the system and now let's do some EDA on the dataset to better understand our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wQzTRdm0tYg"
      },
      "source": [
        "# 4. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVaYGLc94aGm"
      },
      "source": [
        "## 4.1: When were the movies released?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iwB_2Cm24FL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ec8168ab-8298-4597-90e1-3d7e27d688bb"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
        "\n",
        "data = movie_titles['Year'].value_counts().sort_index()\n",
        "x = data.index.map(int)\n",
        "y = data.values\n",
        "\n",
        "sns.barplot(x, y)\n",
        "xmin, xmax = plt.xlim()\n",
        "xtick_labels = [x[0]] + list(x[10:-10:10]) + [x[-1]]\n",
        "plt.xticks(ticks=np.linspace(xmin, xmax, 10), labels=xtick_labels);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2mWAym5rBL"
      },
      "source": [
        "Many movies on Netflix have been released in this millennial. Whether Netflix prefers young movies or there are no old movies left can not be deduced from this plot.\n",
        "The decline for the rightmost point is probably caused by an incomplete last year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QACzcP3w4z6j"
      },
      "source": [
        "## Q 4.2: How are The Ratings Distributed?\n",
        "\n",
        "__Your Turn:__ Build the visualization for rating distributions similar to the previous plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Mvv0w124FP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8ff11d72-2a2c-42ef-b291-a3113f01ddd6"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
        "\n",
        "data = df['Rating'].value_counts().sort_index()\n",
        "x = data.index.map(int)\n",
        "y = data.values\n",
        "\n",
        "sns.barplot(x, y)\n",
        "plt.xticks(ticks=range(len(x)), labels=x)\n",
        "plt.xlabel('Rating')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn5uhmcu5xCE"
      },
      "source": [
        "Netflix movies rarely have a rating lower than three. Most ratings have between three and four stars.\n",
        "The distribution is probably biased, since only people liking the movies proceed to be customers and others presumably will leave the platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQwkKk935eRl"
      },
      "source": [
        "## 4.3: Visualize the Distribution of Number of Movie Ratings \n",
        "\n",
        "This is to understand how many movies (y-axis) are receiving specific number of movie ratings (x-axis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yatEt4eE24FS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "5fd45a7f-d806-46a9-fbeb-9e963d34f861"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "data = df.groupby('Movie')['Rating'].count()\n",
        "sns.distplot(data[data  < 10000], kde=False, ax=ax[0]);\n",
        "sns.distplot(data[data  > 10000], kde=False, ax=ax[1]);"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS5we5r4-nyV"
      },
      "source": [
        "## Q 4.4: Visualize the Distribution of Number of User Ratings \n",
        "\n",
        "This is to understand how many users (y-axis) are giving specific number of movie ratings (x-axis)\n",
        "\n",
        "__Your Turn:__ Try to find out an optimal threshold as in the previous example to split the data to form two understandable subplots!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf-Q6jP-24FV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "533d3629-4d76-49f0-b97e-de3f0ab27e2e"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "data = df.groupby('User')['Movie'].count()\n",
        "sns.distplot(data[data  < 500], kde=False, ax=ax[0]);\n",
        "sns.distplot(data[data  > 500], kde=False, ax=ax[1]);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMOY1tG75i24"
      },
      "source": [
        "The ratings per movie as well as the ratings per user both have nearly a perfect exponential decay. Only very few movies/users have many ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5S7Q14L_CL1"
      },
      "source": [
        "# 5. Dimensionality Reduction & Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5YZwbcH7LzU"
      },
      "source": [
        "## Filter Sparse Movies And Users\n",
        "\n",
        "To reduce the dimensionality of the dataset I am filtering rarely rated movies and rarely rating users out.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nwtEkvSFFK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf3356c-0cde-47fb-85bb-9bf4f60b59f0"
      },
      "source": [
        "# Filter sparse movies\n",
        "min_movie_ratings = 1000\n",
        "filter_movies = (df['Movie'].value_counts()>min_movie_ratings)\n",
        "filter_movies = filter_movies[filter_movies].index.tolist()\n",
        "\n",
        "# Filter sparse users\n",
        "min_user_ratings = 200\n",
        "filter_users = (df['User'].value_counts()>min_user_ratings)\n",
        "filter_users = filter_users[filter_users].index.tolist()\n",
        "\n",
        "# Actual filtering\n",
        "df_filtered = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n",
        "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
        "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
        "print('Shape User-Ratings filtered:\\t{}'.format(df_filtered.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape User-Ratings unfiltered:\t(24053764, 4)\n",
            "Shape User-Ratings filtered:\t(5930581, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQ4JmM67TYQ"
      },
      "source": [
        "After filtering sparse movies and users about 5.9M rating records are present."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI1CoJP9_kbF"
      },
      "source": [
        "# 6. Create Train and Test Datasets\n",
        "\n",
        "Do note this will be used for the statistical method based models and collaborative filtering.\n",
        "\n",
        "For content based filtering it is more of a model which recommends movies rather than predicting ratings and for the hybrid model we will need to recreate the train and test datasets later since we need to create a subset of movies-users-ratings which have movie text descriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7LX0sob7a2Z"
      },
      "source": [
        "## Create Train and Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyCrLAoFFHm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcd1493-8680-4a71-c810-95a6329000f1"
      },
      "source": [
        "# Shuffle DataFrame\n",
        "df_filtered = df_filtered.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Testingsize\n",
        "n = 100000\n",
        "\n",
        "# Split train- & testset\n",
        "df_train = df_filtered[:-n]\n",
        "df_test = df_filtered[-n:]\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5830581, 3), (100000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQjPE9-76iP"
      },
      "source": [
        "The train set will be used to train all models and the test set ensures we can compare model performance on unseen data using the RMSE metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufn47cGh_wNC"
      },
      "source": [
        "# 7. Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWkzhX-a792R"
      },
      "source": [
        "### Q 7.1: Transform The User-Movie-Ratings Data Frame to User-Movie Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDeuv70i8NMQ"
      },
      "source": [
        "A large, sparse matrix will be created in this step. Each row will represent a user and its ratings and the columns are the movies.\n",
        "\n",
        "The movies already rated by users are the non-empty values in the matrix.\n",
        "\n",
        "Empty values are unrated movies and the main objective is to estimate the empty values to help our users.\n",
        "\n",
        "\n",
        "__Your turn:__ Create the User-Movie matrix leveraging the __`pivot_table()`__ function from pandas.\n",
        "\n",
        "Fill in the blanks in the code below by referencing the __`pivot_table()`__ function and invoking it on __`df_train`__. Feel free to check out the documentation.\n",
        "\n",
        "Remember, rows should be users, columns should be movies and the values in the matrix should be the movie ratings. All these should be available in the __`df_train`__ dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ieAea92FJye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "94b6b060-2240-4d23-b6dc-0267ce782996"
      },
      "source": [
        "# Create a user-movie matrix with empty values\n",
        "df_p = pd.pivot_table(df_train, values='Rating', index='User', columns='Movie')\n",
        "print('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\n",
        "df_p.head(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape User-Movie-Matrix:\t(20828, 1741)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Movie</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>28</th>\n",
              "      <th>30</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>52</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>68</th>\n",
              "      <th>71</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>81</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>97</th>\n",
              "      <th>104</th>\n",
              "      <th>108</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>113</th>\n",
              "      <th>116</th>\n",
              "      <th>...</th>\n",
              "      <th>4396</th>\n",
              "      <th>4398</th>\n",
              "      <th>4402</th>\n",
              "      <th>4405</th>\n",
              "      <th>4407</th>\n",
              "      <th>4411</th>\n",
              "      <th>4413</th>\n",
              "      <th>4414</th>\n",
              "      <th>4415</th>\n",
              "      <th>4418</th>\n",
              "      <th>4419</th>\n",
              "      <th>4420</th>\n",
              "      <th>4427</th>\n",
              "      <th>4429</th>\n",
              "      <th>4432</th>\n",
              "      <th>4438</th>\n",
              "      <th>4441</th>\n",
              "      <th>4442</th>\n",
              "      <th>4449</th>\n",
              "      <th>4450</th>\n",
              "      <th>4454</th>\n",
              "      <th>4456</th>\n",
              "      <th>4460</th>\n",
              "      <th>4463</th>\n",
              "      <th>4465</th>\n",
              "      <th>4468</th>\n",
              "      <th>4472</th>\n",
              "      <th>4474</th>\n",
              "      <th>4478</th>\n",
              "      <th>4479</th>\n",
              "      <th>4482</th>\n",
              "      <th>4483</th>\n",
              "      <th>4484</th>\n",
              "      <th>4485</th>\n",
              "      <th>4488</th>\n",
              "      <th>4489</th>\n",
              "      <th>4490</th>\n",
              "      <th>4492</th>\n",
              "      <th>4493</th>\n",
              "      <th>4496</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>User</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000079</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000192</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000301</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000387</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000410</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000527</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000596</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000634</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000710</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000779</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1741 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Movie    3     5     6     8     16    17    ...  4488  4489  4490  4492  4493  4496\n",
              "User                                         ...                                    \n",
              "1000079   NaN   NaN   NaN   NaN   NaN   NaN  ...   2.0   NaN   NaN   NaN   NaN   NaN\n",
              "1000192   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
              "1000301   NaN   NaN   NaN   NaN   NaN   NaN  ...   4.0   NaN   NaN   NaN   NaN   NaN\n",
              "1000387   NaN   NaN   NaN   NaN   NaN   NaN  ...   2.0   NaN   NaN   1.0   NaN   NaN\n",
              "1000410   NaN   NaN   NaN   NaN   NaN   NaN  ...   3.0   NaN   3.0   NaN   NaN   3.0\n",
              "1000527   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   3.0   NaN\n",
              "1000596   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
              "1000634   NaN   NaN   NaN   NaN   NaN   NaN  ...   4.0   NaN   NaN   4.0   NaN   NaN\n",
              "1000710   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN\n",
              "1000779   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   4.0\n",
              "\n",
              "[10 rows x 1741 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojO2T5Ti_4TG"
      },
      "source": [
        "## 8. Building Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOrqqL3KDn9L"
      },
      "source": [
        "## 8.1(a): Global Recommendation Systems (Mean Rating)\n",
        "\n",
        "Computing the mean rating for all movies creates a ranking. The recommendation will be the same for all users and can be used if there is no information on the user.\n",
        "Variations of this approach can be separate rankings for each country/year/gender/... and to use them individually to recommend movies/items to the user.\n",
        "\n",
        "It has to be noted that this approach is biased and favours movies with fewer ratings, since large numbers of ratings tend to be less extreme in its mean ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlIuNnXxONlb"
      },
      "source": [
        "### Additional Hint\n",
        "\n",
        "Predict model performance: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spUQbaIz24Fo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a95252bd-330e-44b1-b953-96466a783545"
      },
      "source": [
        "# Compute mean rating for all movies\n",
        "ratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n",
        "\n",
        "# Compute rating frequencies for all movies\n",
        "ratings_count = df_p.count(axis=0).rename('Rating-Freq').to_frame()\n",
        "\n",
        "# Combine the aggregated dataframes\n",
        "combined_df = ratings_mean.join(ratings_count).join(movie_titles)\n",
        "combined_df.head(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating-Mean</th>\n",
              "      <th>Rating-Freq</th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>4.662567</td>\n",
              "      <td>1301</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Lost: Season 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2102</th>\n",
              "      <td>4.508050</td>\n",
              "      <td>2795</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>The Simpsons: Season 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3444</th>\n",
              "      <td>4.433701</td>\n",
              "      <td>2813</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Family Guy: Freakin' Sweet Collection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>4.425555</td>\n",
              "      <td>18611</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>4.388002</td>\n",
              "      <td>6201</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>The Simpsons: Season 3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Rating-Mean  ...                                           Name\n",
              "Movie               ...                                               \n",
              "3456      4.662567  ...                                 Lost: Season 1\n",
              "2102      4.508050  ...                         The Simpsons: Season 6\n",
              "3444      4.433701  ...          Family Guy: Freakin' Sweet Collection\n",
              "2452      4.425555  ...  Lord of the Rings: The Fellowship of the Ring\n",
              "2172      4.388002  ...                         The Simpsons: Season 3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf66eVE_24Fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c6d6a19a-8396-4eaf-a1da-eb6e41b77430"
      },
      "source": [
        "# Join labels and predictions based on mean movie rating\n",
        "predictions_df = df_test.set_index('Movie').join(ratings_mean)\n",
        "predictions_df.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating-Mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>917063</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.449248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>341649</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.449248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1252629</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.449248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>709342</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.449248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1500112</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.449248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          User  Rating  Rating-Mean\n",
              "Movie                              \n",
              "3       917063     4.0     3.449248\n",
              "3       341649     3.0     3.449248\n",
              "3      1252629     4.0     3.449248\n",
              "3       709342     4.0     3.449248\n",
              "3      1500112     4.0     3.449248"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W2txAub24Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dfecf6-e7d6-4476-8124-988cfe6291d9"
      },
      "source": [
        "# Compute RMSE\n",
        "y_true = predictions_df['Rating']\n",
        "y_pred = predictions_df['Rating-Mean']\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
        "print(\"The RMSE Value for the Mean Rating Recommender:\", rmse)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE Value for the Mean Rating Recommender: 1.009627841349999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xda52K1m24Fu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "23209980-2749-497a-ae4a-032b0ef24df7"
      },
      "source": [
        "# View top ten rated movies\n",
        "combined_df[['Name', 'Rating-Mean']].head(10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Rating-Mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>Lost: Season 1</td>\n",
              "      <td>4.662567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2102</th>\n",
              "      <td>The Simpsons: Season 6</td>\n",
              "      <td>4.508050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3444</th>\n",
              "      <td>Family Guy: Freakin' Sweet Collection</td>\n",
              "      <td>4.433701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
              "      <td>4.425555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>The Simpsons: Season 3</td>\n",
              "      <td>4.388002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>The Best of Friends: Vol. 4</td>\n",
              "      <td>4.369477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>Finding Nemo (Widescreen)</td>\n",
              "      <td>4.369232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>Six Feet Under: Season 4</td>\n",
              "      <td>4.350973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4238</th>\n",
              "      <td>Inu-Yasha</td>\n",
              "      <td>4.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3046</th>\n",
              "      <td>The Simpsons: Treehouse of Horror</td>\n",
              "      <td>4.347930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Name  Rating-Mean\n",
              "Movie                                                            \n",
              "3456                                  Lost: Season 1     4.662567\n",
              "2102                          The Simpsons: Season 6     4.508050\n",
              "3444           Family Guy: Freakin' Sweet Collection     4.433701\n",
              "2452   Lord of the Rings: The Fellowship of the Ring     4.425555\n",
              "2172                          The Simpsons: Season 3     4.388002\n",
              "1256                     The Best of Friends: Vol. 4     4.369477\n",
              "3962                       Finding Nemo (Widescreen)     4.369232\n",
              "1476                        Six Feet Under: Season 4     4.350973\n",
              "4238                                       Inu-Yasha     4.350000\n",
              "3046               The Simpsons: Treehouse of Horror     4.347930"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFalvivYD1Is"
      },
      "source": [
        "## Q 8.1(b): Global Recommendation Systems (Weighted Rating)\n",
        "\n",
        "To tackle the problem of the unstable mean with few ratings e.g. IDMb uses a weighted rating. Many good ratings outweigh few in this algorithm.\n",
        "\n",
        "### Hint:\n",
        "\n",
        "Weighted Rating Formula\n",
        "\n",
        "weighted rating (𝑊𝑅)=(𝑣/(𝑣+𝑚))𝑅+(𝑚/(𝑣+𝑚))𝐶\n",
        "\n",
        "where:\n",
        "\n",
        "*𝑅* = average for the movie (mean) = (Rating)\n",
        "\n",
        "*𝑣* = number of votes for the movie = (votes)\n",
        "\n",
        "*𝑚* = minimum votes required \n",
        "\n",
        "*𝐶* = the mean vote across the whole report \n",
        "\n",
        "__Your Turn:__ Fill in the necessary code snippets below to build and test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVfj7TPz24Fz"
      },
      "source": [
        "# Number of minimum votes to be considered\n",
        "m = 1000\n",
        "\n",
        "# Mean rating for all movies\n",
        "C = df_p.stack().mean()\n",
        "\n",
        "# Mean rating for all movies separately\n",
        "R = df_p.mean(axis=0).values\n",
        "\n",
        "# Rating freqency for all movies separately\n",
        "v = df_p.count().values"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntm_D7Yl24F1"
      },
      "source": [
        "# Weighted formula to compute the weighted rating\n",
        "weighted_score = (v/(v+m))*R+(m/(v+m))*C"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQe4smBk24F3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c837049a-0aaa-47ff-e526-52e566a45cb2"
      },
      "source": [
        "# convert weighted_score into a dataframe\n",
        "weighted_mean = pd.DataFrame(data=weighted_score, index=df_p.count().index, columns=['Weighted Mean']).sort_values(by='Weighted Mean', ascending=False)\n",
        "\n",
        "# Combine the aggregated dataframes (wighted_mean & movie_titles)\n",
        "combined_df = weighted_mean.join(movie_titles)\n",
        "combined_df.head(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted Mean</th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>4.376726</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>4.320425</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>Finding Nemo (Widescreen)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4306</th>\n",
              "      <td>4.288563</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>The Sixth Sense</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2862</th>\n",
              "      <td>4.281447</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>The Silence of the Lambs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3290</th>\n",
              "      <td>4.264766</td>\n",
              "      <td>1974.0</td>\n",
              "      <td>The Godfather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Weighted Mean    Year                                           Name\n",
              "Movie                                                                      \n",
              "2452        4.376726  2001.0  Lord of the Rings: The Fellowship of the Ring\n",
              "3962        4.320425  2003.0                      Finding Nemo (Widescreen)\n",
              "4306        4.288563  1999.0                                The Sixth Sense\n",
              "2862        4.281447  1991.0                       The Silence of the Lambs\n",
              "3290        4.264766  1974.0                                  The Godfather"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMd68xuj24F5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8155be8c-79ec-45dc-c465-926fde826efc"
      },
      "source": [
        "# Join labels and predictions based on mean movie rating\n",
        "predictions_df = df_test.set_index('Movie').join(weighted_mean)\n",
        "predictions_df.head(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weighted Mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>917063</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.461465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>341649</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.461465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1252629</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.461465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>709342</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.461465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1500112</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.461465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          User  Rating  Weighted Mean\n",
              "Movie                                \n",
              "3       917063     4.0       3.461465\n",
              "3       341649     3.0       3.461465\n",
              "3      1252629     4.0       3.461465\n",
              "3       709342     4.0       3.461465\n",
              "3      1500112     4.0       3.461465"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdCxHIO424F8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b404b937-b8cd-4042-dd7e-eb0567731c21"
      },
      "source": [
        "# Compute RMSE\n",
        "y_true = predictions_df['Rating']\n",
        "y_pred = predictions_df['Weighted Mean']\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
        "print(\"The RMSE Value for the Weighted-Mean Rating Recommender:\", rmse)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE Value for the Weighted-Mean Rating Recommender: 1.0156309764137332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt1Q5Mh124F-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "658bb9cb-ff9e-48da-e686-828fa39fdbc3"
      },
      "source": [
        "# View top ten rated movies\n",
        "combined_df.head(10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted Mean</th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>4.376726</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>4.320425</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>Finding Nemo (Widescreen)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4306</th>\n",
              "      <td>4.288563</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>The Sixth Sense</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2862</th>\n",
              "      <td>4.281447</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>The Silence of the Lambs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3290</th>\n",
              "      <td>4.264766</td>\n",
              "      <td>1974.0</td>\n",
              "      <td>The Godfather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>4.260237</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>The Simpsons: Season 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2102</th>\n",
              "      <td>4.233983</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>The Simpsons: Season 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2782</th>\n",
              "      <td>4.216655</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>Braveheart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3046</th>\n",
              "      <td>4.201853</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>The Simpsons: Treehouse of Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>4.183683</td>\n",
              "      <td>2005.0</td>\n",
              "      <td>Batman Begins</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Weighted Mean    Year                                           Name\n",
              "Movie                                                                      \n",
              "2452        4.376726  2001.0  Lord of the Rings: The Fellowship of the Ring\n",
              "3962        4.320425  2003.0                      Finding Nemo (Widescreen)\n",
              "4306        4.288563  1999.0                                The Sixth Sense\n",
              "2862        4.281447  1991.0                       The Silence of the Lambs\n",
              "3290        4.264766  1974.0                                  The Godfather\n",
              "2172        4.260237  1991.0                         The Simpsons: Season 3\n",
              "2102        4.233983  1994.0                         The Simpsons: Season 6\n",
              "2782        4.216655  1995.0                                     Braveheart\n",
              "3046        4.201853  1990.0              The Simpsons: Treehouse of Horror\n",
              "3864        4.183683  2005.0                                  Batman Begins"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXa7l21yE-eY"
      },
      "source": [
        "The variable \"m\" can be seen as regularizing parameter. Changing it determines how much weight is put onto the movies with many ratings.\n",
        "Even if there is a better ranking the RMSE decreased slightly. There is a trade-off between interpretability and predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KRZO1u_24GB"
      },
      "source": [
        "## 8.2: Content Based Recommendation Systems\n",
        "\n",
        "\n",
        "The Content-Based Recommender relies on the similarity of the items being recommended. The basic idea is that if you like an item, then you will also like a “similar” item. It generally works well when it’s easy to determine the context/properties of each item. If there is no historical data for a user or there is reliable metadata for each movie, it can be useful to compare the metadata of the movies to find similar ones.\n",
        "\n",
        "![](./images/Content-based.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WovG-3YFSqo"
      },
      "source": [
        "### Cosine TFIDF Movie Description Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eldw_9lpNfUJ"
      },
      "source": [
        "#### TF-IDF \n",
        "\n",
        "This is a text vectorization technique which is used to determine the relative importance of a document / article / news item / movie etc.\n",
        "\n",
        "TF is simply the frequency of a word in a document. \n",
        "\n",
        "IDF is the inverse of the document frequency among the whole corpus of documents. \n",
        "\n",
        "TF-IDF is used mainly because of two reasons: Suppose we search for “the results of latest European Socccer games” on Google. It is certain that “the” will occur more frequently than “soccer games” but the relative importance of soccer games is higher than the search query point of view. \n",
        "\n",
        "In such cases, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item (document).\n",
        "\n",
        "![](./images/TF-IDF-FORMULA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trb9DlZxOYGO"
      },
      "source": [
        "#### Cosine Similarity \n",
        "After calculating TF-IDF scores, how do we determine which items are closer to each other, rather closer to the user profile? This is accomplished using the Vector Space Model which computes the proximity based on the angle between the vectors.\n",
        "\n",
        "Consider the following example\n",
        "\n",
        "![](./images/vector-space-model.png)\n",
        "\n",
        "Sentence 2 is more likely to be using Term 2 than using Term 1. Vice-versa for Sentence 1. \n",
        "\n",
        "The method of calculating this relative measure is calculated by taking the cosine of the angle between the sentences and the terms. \n",
        "\n",
        "The ultimate reason behind using cosine is that the value of cosine will increase with decreasing value of the angle between which signifies more similarity. \n",
        "\n",
        "The vectors are length normalized after which they become vectors of length 1 and then the cosine calculation is simply the sum-product of vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cm9mjG-PSr3"
      },
      "source": [
        "In this approch we will use the movie description to create a TFIDF-matrix, which counts and weights words in all descriptions, and compute a cosine similarity between all of those sparse text-vectors. This can easily be extended to more or different features if you like.\n",
        "It is impossible for this model to compute a RMSE score, since the model does not recommend the movies directly.\n",
        "In this way it is possible to find movies closly related to each other.\n",
        "\n",
        "This approach of content based filtering can be extendend to increase the model performance by adding some more features like genres, cast, crew etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdEeBvSf24GE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17c1729-22c3-4452-9c56-12601ceb5596"
      },
      "source": [
        "# view sample movie descriptions\n",
        "movie_metadata['overview'].head(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "original_title\n",
              "Toy Story                      Led by Woody, Andy's toys live happily in his ...\n",
              "Jumanji                        When siblings Judy and Peter discover an encha...\n",
              "Grumpier Old Men               A family wedding reignites the ancient feud be...\n",
              "Waiting to Exhale              Cheated on, mistreated and stepped on, the wom...\n",
              "Father of the Bride Part II    Just when George Banks has recovered from his ...\n",
              "Name: overview, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiiwYdQj24GG"
      },
      "source": [
        "# Create tf-idf matrix for text comparison\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU3Kr_OJ24GK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "40a409b8-3bc1-42cb-d720-43adfcbd7baa"
      },
      "source": [
        "# Compute cosine similarity between all movie-descriptions\n",
        "similarity = cosine_similarity(tfidf_matrix)\n",
        "similarity_df = pd.DataFrame(similarity, \n",
        "                             index=movie_metadata.index.values, \n",
        "                             columns=movie_metadata.index.values)\n",
        "similarity_df.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Toy Story</th>\n",
              "      <th>Jumanji</th>\n",
              "      <th>Grumpier Old Men</th>\n",
              "      <th>Waiting to Exhale</th>\n",
              "      <th>Father of the Bride Part II</th>\n",
              "      <th>Heat</th>\n",
              "      <th>Sabrina</th>\n",
              "      <th>Tom and Huck</th>\n",
              "      <th>Sudden Death</th>\n",
              "      <th>GoldenEye</th>\n",
              "      <th>The American President</th>\n",
              "      <th>Dracula: Dead and Loving It</th>\n",
              "      <th>Balto</th>\n",
              "      <th>Nixon</th>\n",
              "      <th>Cutthroat Island</th>\n",
              "      <th>Casino</th>\n",
              "      <th>Sense and Sensibility</th>\n",
              "      <th>Four Rooms</th>\n",
              "      <th>Ace Ventura: When Nature Calls</th>\n",
              "      <th>Money Train</th>\n",
              "      <th>Get Shorty</th>\n",
              "      <th>Copycat</th>\n",
              "      <th>Assassins</th>\n",
              "      <th>Powder</th>\n",
              "      <th>Leaving Las Vegas</th>\n",
              "      <th>Othello</th>\n",
              "      <th>Now and Then</th>\n",
              "      <th>Persuasion</th>\n",
              "      <th>La Cité des Enfants Perdus</th>\n",
              "      <th>摇啊摇，摇到外婆桥</th>\n",
              "      <th>Dangerous Minds</th>\n",
              "      <th>Twelve Monkeys</th>\n",
              "      <th>Babe</th>\n",
              "      <th>Carrington</th>\n",
              "      <th>Dead Man Walking</th>\n",
              "      <th>It Takes Two</th>\n",
              "      <th>Clueless</th>\n",
              "      <th>Cry, the Beloved Country</th>\n",
              "      <th>Richard III</th>\n",
              "      <th>Dead Presidents</th>\n",
              "      <th>...</th>\n",
              "      <th>Quiz</th>\n",
              "      <th>Minions: Orientation Day</th>\n",
              "      <th>Descendants 2</th>\n",
              "      <th>La lune à un mètre</th>\n",
              "      <th>L'Illusionniste fin de siècle</th>\n",
              "      <th>Turist</th>\n",
              "      <th>Pattaya</th>\n",
              "      <th>Lou</th>\n",
              "      <th>Gideon's Daughter</th>\n",
              "      <th>La Fille du 14 juillet</th>\n",
              "      <th>El olivo</th>\n",
              "      <th>American Violence</th>\n",
              "      <th>À bras ouverts</th>\n",
              "      <th>Les Visiteurs: La Révolution</th>\n",
              "      <th>Titanic II</th>\n",
              "      <th>Rasputin: The Mad Monk</th>\n",
              "      <th>House of the Long Shadows</th>\n",
              "      <th>Frankenstein Created Woman</th>\n",
              "      <th>Return to the Batcave: The Misadventures of Adam and Burt</th>\n",
              "      <th>Follow That Camel</th>\n",
              "      <th>Carry On Camping</th>\n",
              "      <th>The Pope Must Die</th>\n",
              "      <th>Carry On England</th>\n",
              "      <th>Take Me</th>\n",
              "      <th>फिल्लौरी</th>\n",
              "      <th>The Incredible Jessica James</th>\n",
              "      <th>It Stains the Sands Red</th>\n",
              "      <th>Baignade en Mer</th>\n",
              "      <th>Arabian Nights</th>\n",
              "      <th>Xiao Wu</th>\n",
              "      <th>The Final Storm</th>\n",
              "      <th>In a Heartbeat</th>\n",
              "      <th>Bloed, Zweet en Tranen</th>\n",
              "      <th>To Be Fat Like Me</th>\n",
              "      <th>Cadet Kelly</th>\n",
              "      <th>L'Homme à la tête de caoutchouc</th>\n",
              "      <th>Le locataire diabolique</th>\n",
              "      <th>L'Homme orchestre</th>\n",
              "      <th>Maa</th>\n",
              "      <th>Robin Hood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Toy Story</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009716</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019101</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jumanji</th>\n",
              "      <td>0.015385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.046854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007711</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021428</td>\n",
              "      <td>0.02181</td>\n",
              "      <td>0.006329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045385</td>\n",
              "      <td>0.005210</td>\n",
              "      <td>0.00405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.181517</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021986</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grumpier Old Men</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046854</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023903</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.011698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006426</td>\n",
              "      <td>0.006611</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012547</td>\n",
              "      <td>0.011927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009830</td>\n",
              "      <td>0.014365</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022128</td>\n",
              "      <td>0.020168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036402</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007101</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Waiting to Exhale</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014870</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.015617</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020834</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007782</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.007745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008871</td>\n",
              "      <td>0.007586</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012761</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010317</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040390</td>\n",
              "      <td>0.028460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016324</td>\n",
              "      <td>0.006840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Father of the Bride Part II</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023903</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.010366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011918</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011851</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011278</td>\n",
              "      <td>0.025584</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008279</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016894</td>\n",
              "      <td>0.05114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017736</td>\n",
              "      <td>0.052974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012584</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heat</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024788</td>\n",
              "      <td>0.032075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030579</td>\n",
              "      <td>0.005867</td>\n",
              "      <td>0.007578</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023886</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.007513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075501</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016985</td>\n",
              "      <td>0.036003</td>\n",
              "      <td>0.010008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sabrina</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034207</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tom and Huck</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.008592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018394</td>\n",
              "      <td>0.005528</td>\n",
              "      <td>0.050006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011342</td>\n",
              "      <td>0.006287</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010889</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004665</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.048852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029281</td>\n",
              "      <td>0.164136</td>\n",
              "      <td>0.071019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006162</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sudden Death</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033213</td>\n",
              "      <td>0.046349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029766</td>\n",
              "      <td>0.023356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016458</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.017412</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.157950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020428</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019882</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.009625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024666</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014963</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GoldenEye</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017620</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.023622</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043867</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016266</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 21604 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Toy Story   Jumanji  ...       Maa  Robin Hood\n",
              "Toy Story                     1.000000  0.015385  ...  0.000000         0.0\n",
              "Jumanji                       0.015385  1.000000  ...  0.000000         0.0\n",
              "Grumpier Old Men              0.000000  0.046854  ...  0.007101         0.0\n",
              "Waiting to Exhale             0.000000  0.000000  ...  0.000000         0.0\n",
              "Father of the Bride Part II   0.000000  0.000000  ...  0.012584         0.0\n",
              "Heat                          0.000000  0.047646  ...  0.000000         0.0\n",
              "Sabrina                       0.000000  0.000000  ...  0.000000         0.0\n",
              "Tom and Huck                  0.000000  0.000000  ...  0.006162         0.0\n",
              "Sudden Death                  0.000000  0.098488  ...  0.014963         0.0\n",
              "GoldenEye                     0.000000  0.000000  ...  0.000000         0.0\n",
              "\n",
              "[10 rows x 21604 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm2sEuOs24GN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bdeea26-28f0-4d10-ab4d-ad9b2fc3ee78"
      },
      "source": [
        "# movie list \n",
        "movie_list = similarity_df.columns.values\n",
        "\n",
        "\n",
        "# sample movie\n",
        "movie = 'Batman Begins'\n",
        "\n",
        "# top recommendation movie count\n",
        "top_n = 10\n",
        "\n",
        "# get movie similarity records\n",
        "movie_sim = similarity_df[similarity_df.index == movie].values[0]\n",
        "\n",
        "# get movies sorted by similarity\n",
        "sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
        "\n",
        "# get recommended movie names\n",
        "recommended_movies = movie_list[sorted_movie_ids[1:top_n+1]]\n",
        "\n",
        "print('\\n\\nTop Recommended Movies for:', movie, 'are:-\\n', recommended_movies)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Top Recommended Movies for: Batman Begins are:-\n",
            " ['Batman Unmasked: The Psychology of the Dark Knight'\n",
            " 'Batman: The Dark Knight Returns, Part 1' 'Batman: Bad Blood'\n",
            " 'Batman: Year One' 'Batman: Under the Red Hood'\n",
            " 'Batman Beyond: The Movie' 'Batman Forever'\n",
            " 'Batman: Mask of the Phantasm' 'Batman & Bill' 'Batman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50vzONVBqkTu"
      },
      "source": [
        "__Your turn:__ Create a function as defined below, __`content_movie_recommender()`__ which can take in sample movie names and print a list of top N recommended movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5cyFCvp24GT"
      },
      "source": [
        "def content_movie_recommender(input_movie, similarity_database=similarity_df, movie_database_list=movie_list, top_n=10):\n",
        "    # get movie similarity records\n",
        "    movie_sim = similarity_df[similarity_df.index == input_movie].values[0]\n",
        "\n",
        "    # get movies sorted by similarity\n",
        "    sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
        "\n",
        "    # get recommended movie names\n",
        "    recommended_movies = movie_database_list[sorted_movie_ids[1:top_n+1]]\n",
        "\n",
        "    print('\\n\\nTop Recommended Movies for:', input_movie, 'are:-\\n', recommended_movies)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR0sKcxIqxql"
      },
      "source": [
        "__Your turn:__ Test your function below on the given sample movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0tUINS_24GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81523f4-d903-44dd-e07c-1b2b73c5bb10"
      },
      "source": [
        "sample_movies = ['Captain America', 'The Terminator', 'The Exorcist', \n",
        "                 'The Hunger Games: Mockingjay - Part 1', 'The Blair Witch Project']\n",
        "                 \n",
        "for m in sample_movies:\n",
        "    content_movie_recommender(m, top_n=3)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Top Recommended Movies for: Captain America are:-\n",
            " ['Iron Man & Captain America: Heroes United'\n",
            " 'Captain America: The First Avenger' 'Team Thor']\n",
            "\n",
            "\n",
            "Top Recommended Movies for: The Terminator are:-\n",
            " ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
            " 'Terminator 3: Rise of the Machines']\n",
            "\n",
            "\n",
            "Top Recommended Movies for: The Exorcist are:-\n",
            " ['Exorcist II: The Heretic' 'Domestic Disturbance' 'Damien: Omen II']\n",
            "\n",
            "\n",
            "Top Recommended Movies for: The Hunger Games: Mockingjay - Part 1 are:-\n",
            " ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
            " 'Last Train from Gun Hill']\n",
            "\n",
            "\n",
            "Top Recommended Movies for: The Blair Witch Project are:-\n",
            " ['Book of Shadows: Blair Witch 2' 'Freakonomics' 'Le Bal des actrices']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3fofy8frA2k"
      },
      "source": [
        "## 8.3: Collaborative filtering Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Su_sBArKWX"
      },
      "source": [
        "### Collaborative Filtering\n",
        "Primarily recommends content to you based on inputs or actions from other people(say your friends).\n",
        "![collaborative filtering](./images/collaborative-filtering.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxRJfswzrN5A"
      },
      "source": [
        "### What is the intuition behind this?\n",
        "\n",
        "*   **Personal tastes are correlated**\n",
        "\n",
        "\n",
        "        1.   If Alice and Bob both like X and Alice likes Y then Bob is more likely to like Y\n",
        "        2.   especially (perhaps) if Bob knows Alice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUoI6lh6rSlG"
      },
      "source": [
        "Types of Collaborative Filtering:\n",
        "\n",
        "\n",
        "1.   Neighborhood methods\n",
        "2.   Matrix Factorization (Latent Factor) methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23PnmU-FraW8"
      },
      "source": [
        "Assume you dont have users. Rather you have users' characterisics and properties(as shown in image).![Latent Factor method](https://miro.medium.com/max/876/1*AQEx38Wdo5H0WTSjRfAWtA.png)\n",
        "\n",
        "For example, a person who is brave-hearted is more likely to be interested in dark, horrific movies rather than someone who is soft and compassionate.\n",
        "* ^This is just an example(not in any literal sense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidNZWZXrdmt"
      },
      "source": [
        "So, once you have the properties and characteristics of each user, we call them as lower-dimensional features of the users. Similarly, we can have lower-dimensional features for movies(say its 10% action, 20% romance ...)\n",
        "\n",
        "With these features, we represent users and movies in a low dimensional space describing their properties. **This is called as the latent space.**\n",
        "\n",
        "We then recommend a movie based on its proximity to the user in the latent space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InGsgab1rhVT"
      },
      "source": [
        "### The problem:\n",
        "\n",
        "The problem we try to address here is the rating prediction problem. \n",
        "Say, we try to guess how much Alice would rate a movie and suggest those movies that we think Alice will rate higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDZRCzhrijy"
      },
      "source": [
        "### Interesting...But, how do we predict how much Alice would rate a movie?\n",
        "\n",
        " The data we have is a rating history: ratings of users for items in the interval [1,5]. We can put all this data into a sparse matrix called R:\n",
        " \n",
        " $R = \n",
        " \\begin{pmatrix}\n",
        "  3 & ? &? \\\\ \n",
        "  ? & 4 & 5 \\\\\n",
        "  ? & ? & 2 \\\\\n",
        "  2 & 3 & ?\n",
        " \\end{pmatrix}\n",
        " \\begin{matrix}\n",
        "  Alice \\\\ \n",
        "  Bob \\\\\n",
        "  Chand \\\\\n",
        "  Deb\n",
        " \\end{matrix}\n",
        " $\n",
        "\n",
        " Each row of the matrix corresponds to a given user, and each column corresponds to a given item. For instance here, Alice has rated the first movie with a rating of 3, and Chand has rated the third item with a rating of 2.\n",
        "\n",
        " The matrix R is sparse (more than 99% of the entries are missing), and our goal is to predict the missing entries, i.e. predict the ?.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MeURMvrniQ"
      },
      "source": [
        "### Anatomy of the Rating matrix: LATENT SPACE\n",
        "Before predicting ratings, lets step back and understand the latent space more! \\\\\n",
        " In this Rating matrix, Rows represent Users and Columns represent Movies.\n",
        " $R = \n",
        "  \\begin{pmatrix}\n",
        "  --Alice-- \\\\ \n",
        "  --Bob-- \\\\\n",
        "  --Chand-- \\\\\n",
        "  --Deb--\n",
        " \\end{pmatrix}\n",
        " $\n",
        "\n",
        " In latent space(low dimensional features - fanatics), for instance, Alice could be defined as a little bit of an action fan, a little bit of a comedy fan, a lot of a romance fan, etc. As for Bob, he could be more keen on action movies:\n",
        "\n",
        "```\n",
        "Alice = 10% Action fan + 10% Comedy fan + 50% Romance fan + ⋯ \\\\\n",
        "Bob = 50% Action fan + 30% Comedy fan + 10% Romance fan + ⋯ \\\\\n",
        ": \\\\\n",
        "Zoe = ⋯\n",
        "```\n",
        "\n",
        "What would happen if we transposed our rating matrix? Instead of having users in the rows, we would now have movies, defined as their ratings.\n",
        "\n",
        "$\n",
        "R ^ T = \n",
        "  \\begin{pmatrix}\n",
        "  --Avengers-- \\\\ \n",
        "  --Matrix-- \\\\\n",
        "  --Inception-- \\\\\n",
        "  --Sherlock--\n",
        " \\end{pmatrix}\n",
        "$\n",
        "\n",
        "In the latent space, we will associate a semantic meaning behind each of the  movies, and these semantic meanings(say movie characteristics) can build back all of our original movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ_r91x1rr65"
      },
      "source": [
        "### EXAMPLE\n",
        "In the below example, we convert users and movies to vectors(embeddings) and do dot-product to predict R\n",
        "\n",
        "user vector - U \\\\\n",
        "movies vector - V \\\\\n",
        "$\n",
        "R = U.V\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ynl-aVuf3Dy"
      },
      "source": [
        "### Additional hints:\n",
        "\n",
        "use dataframe map - [map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html)\n",
        "\n",
        "Create tensor - [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input#view-aliases)\n",
        "\n",
        "Create Embedding - [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n",
        "\n",
        "Dot product - [Dot](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot)\n",
        "\n",
        "Fit model : \n",
        "[fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
        "\n",
        "Measure Performance: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpPZfOrDs-Qs"
      },
      "source": [
        "### Q8.3: Building a Deep Learning Matrix Factorization based Collaborative Filtering Recommendation System\n",
        "\n",
        "__Your Turn:__ Fill in the necessary blank code snippets in the following sections to train your own DL collaborative  filtering system\n",
        "\n",
        "#### Create Configuration Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUz12Y_Z24Gh"
      },
      "source": [
        "# Create user and movie-id mapping to convert to numbers\n",
        "user_id_mapping = {id:i for i, id in enumerate(df_filtered['User'].unique())}\n",
        "movie_id_mapping = {id:i for i, id in enumerate(df_filtered['Movie'].unique())}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vjVBUM724Gj"
      },
      "source": [
        "# use dataframe map function to map users & movies to mapped ids based on above mapping\n",
        "train_user_data = df_train['User'].map(user_id_mapping)\n",
        "train_movie_data = df_train['Movie'].map(movie_id_mapping)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lpKylKD24Gl"
      },
      "source": [
        "# do the same for test data\n",
        "test_user_data = df_test['User'].map(user_id_mapping)\n",
        "test_movie_data = df_test['Movie'].map(movie_id_mapping)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GME8vJLp24Gn"
      },
      "source": [
        "# Get input variable-sizes\n",
        "users = len(user_id_mapping)\n",
        "movies = len(movie_id_mapping)\n",
        "embedding_size = 100"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enO8VNVP24Gp"
      },
      "source": [
        "#### Construct Deep Learning Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXpYgst24Gq"
      },
      "source": [
        "# use Input() to create tensors for - 'user' and 'movie'\n",
        "user_id_input = Input(shape=(1,), name='user')\n",
        "movie_id_input = Input(shape=(1,), name='movie')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdV4lJri24Gs"
      },
      "source": [
        "# Create embedding layer for users \n",
        "user_embedding = Embedding(output_dim=embedding_size, \n",
        "                           input_dim=users,\n",
        "                           input_length=1, \n",
        "                           name='user_embedding')(user_id_input)\n",
        "\n",
        "# create embedding layer for movies just like users\n",
        "movie_embedding = Embedding(output_dim=embedding_size, \n",
        "                           input_dim=movies,\n",
        "                           input_length=1, \n",
        "                           name='movie_embedding')(movie_id_input)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLpdb0pu24Gu"
      },
      "source": [
        "# Reshape the embedding layers\n",
        "user_vector = Reshape([embedding_size])(user_embedding)\n",
        "movie_vector = Reshape([embedding_size])(movie_embedding)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-RxXy5B24Gw"
      },
      "source": [
        "# Compute dot-product of reshaped embedding layers as prediction\n",
        "y = Dot(1, normalize=False)([user_vector, movie_vector])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wWeeSfR24Gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b687f28-6cee-4a54-958d-18690e340ffe"
      },
      "source": [
        "# Setup model\n",
        "model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "movie (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 100)       2082800     user[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "movie_embedding (Embedding)     (None, 1, 100)       174100      movie[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 100)          0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 100)          0           movie_embedding[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,256,900\n",
            "Trainable params: 2,256,900\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0COamq25owq"
      },
      "source": [
        "#### Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK6aBtQN24Gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee053aa-3057-41b2-a900-d77a57162802"
      },
      "source": [
        "# Fit model\n",
        "X = [train_user_data, train_movie_data]\n",
        "y = df_train['Rating']\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 5\n",
        "validation_split = 0.1\n",
        "\n",
        "model.fit(X, y,\n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs,\n",
        "          validation_split=validation_split,\n",
        "          shuffle=True,\n",
        "          verbose=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5125/5125 [==============================] - 21s 3ms/step - loss: 2.0971 - val_loss: 0.7716\n",
            "Epoch 2/5\n",
            "5125/5125 [==============================] - 18s 3ms/step - loss: 0.7300 - val_loss: 0.7195\n",
            "Epoch 3/5\n",
            "5125/5125 [==============================] - 18s 3ms/step - loss: 0.6668 - val_loss: 0.6958\n",
            "Epoch 4/5\n",
            "5125/5125 [==============================] - 17s 3ms/step - loss: 0.6068 - val_loss: 0.6889\n",
            "Epoch 5/5\n",
            "5125/5125 [==============================] - 17s 3ms/step - loss: 0.5458 - val_loss: 0.7004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70a17896d0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZLw4PX3AUkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbaeb77-1d76-4f99-b31b-0ef76a578597"
      },
      "source": [
        "# Test model by making predictions on test data\n",
        "y_pred = model.predict([test_user_data, test_movie_data]).ravel()\n",
        "# clip upper and lower ratings\n",
        "y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
        "# get true labels\n",
        "y_true = df_test['Rating'].values\n",
        "\n",
        "#  Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
        "print('\\n\\nTesting Result With DL Matrix-Factorization: {:.4f} RMSE'.format(rmse))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Testing Result With DL Matrix-Factorization: 0.8403 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAX4MABlCm-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "b5affbb4-c7b9-4f60-b2ed-9272d9ec8035"
      },
      "source": [
        "## Let's see how our collaborative model performs by seeing the predicted and actual rating for the given user and movie pair\n",
        "results_df = pd.DataFrame({\n",
        "    'User ID': test_user_data.values,\n",
        "    'Movie ID': test_movie_data.values,\n",
        "    'Movie Name': [movie_titles['Name'].iloc[item] for item in test_movie_data],\n",
        "    'Predicted Rating': np.round(y_pred, 1),\n",
        "    'Actual Rating': y_true\n",
        "})\n",
        "\n",
        "results_df.head(20)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Movie ID</th>\n",
              "      <th>Movie Name</th>\n",
              "      <th>Predicted Rating</th>\n",
              "      <th>Actual Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7662</td>\n",
              "      <td>23</td>\n",
              "      <td>My Bloody Valentine</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19414</td>\n",
              "      <td>1080</td>\n",
              "      <td>Back by Midnight</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4952</td>\n",
              "      <td>313</td>\n",
              "      <td>Saturday Night Live: The Best of Jon Lovitz</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9298</td>\n",
              "      <td>404</td>\n",
              "      <td>Wings of Desire</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3461</td>\n",
              "      <td>16</td>\n",
              "      <td>7 Seconds</td>\n",
              "      <td>4.9</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13803</td>\n",
              "      <td>482</td>\n",
              "      <td>Rush Hour 2</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13122</td>\n",
              "      <td>597</td>\n",
              "      <td>Bobby Darin: Mack is Back</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12954</td>\n",
              "      <td>349</td>\n",
              "      <td>Dr. Quinn</td>\n",
              "      <td>3.1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8513</td>\n",
              "      <td>155</td>\n",
              "      <td>Husbands and Wives</td>\n",
              "      <td>2.9</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7418</td>\n",
              "      <td>612</td>\n",
              "      <td>The Dr. Who Collection</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>18540</td>\n",
              "      <td>413</td>\n",
              "      <td>Girl</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>18922</td>\n",
              "      <td>414</td>\n",
              "      <td>Reign in Darkness</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>16738</td>\n",
              "      <td>1249</td>\n",
              "      <td>Brassed Off</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11567</td>\n",
              "      <td>403</td>\n",
              "      <td>The Shaft</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1708</td>\n",
              "      <td>1197</td>\n",
              "      <td>The Cat O'Nine Tails</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15850</td>\n",
              "      <td>81</td>\n",
              "      <td>The Frogmen</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17518</td>\n",
              "      <td>1018</td>\n",
              "      <td>Diamond Hunters</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1708</td>\n",
              "      <td>172</td>\n",
              "      <td>The Devil's Brigade</td>\n",
              "      <td>4.7</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1266</td>\n",
              "      <td>1071</td>\n",
              "      <td>As Time Goes By: Series 8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3827</td>\n",
              "      <td>416</td>\n",
              "      <td>Transformers: Season 3: Part 1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Movie ID  ... Predicted Rating  Actual Rating\n",
              "0      7662        23  ...              3.4            2.0\n",
              "1     19414      1080  ...              4.5            5.0\n",
              "2      4952       313  ...              3.7            4.0\n",
              "3      9298       404  ...              3.2            4.0\n",
              "4      3461        16  ...              4.9            5.0\n",
              "5     13803       482  ...              3.7            2.0\n",
              "6     13122       597  ...              3.2            3.0\n",
              "7     12954       349  ...              3.1            3.0\n",
              "8      8513       155  ...              2.9            5.0\n",
              "9      7418       612  ...              3.8            3.0\n",
              "10    18540       413  ...              3.2            3.0\n",
              "11    18922       414  ...              2.6            3.0\n",
              "12    16738      1249  ...              3.8            2.0\n",
              "13    11567       403  ...              3.4            4.0\n",
              "14     1708      1197  ...              4.5            4.0\n",
              "15    15850        81  ...              3.1            2.0\n",
              "16    17518      1018  ...              2.8            2.0\n",
              "17     1708       172  ...              4.7            5.0\n",
              "18     1266      1071  ...              2.2            2.0\n",
              "19     3827       416  ...              2.6            3.0\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gaq-sJqpc_B_"
      },
      "source": [
        "## 8.4: Hybrid Recommendation System (Content & Collaborative)\n",
        "\n",
        "One advantage of deep learning models is, that movie-metadata can easily be added to the model.\n",
        "We will tf-idf transform the short description of all movies to a sparse vector. The model will learn to reduce the dimensionality of this vector and how to combine metadata with the embedding of the user-id and the movie-id. In this way we can add any additional metadata to our own recommender.\n",
        "These kind of hybrid systems can learn how to reduce the impact of the cold start problem.\n",
        "\n",
        "Deep learning models require lots of data to train and predict. To provide our model with more data, we will include the movie metadata as well. We will do the following:\n",
        "\n",
        "\n",
        "*   Use movie metadata to combine with user and movie matrices in order to get more data\n",
        "*   Use tf-idf transform to vectorize movie metadata (Sparse Layer)\n",
        "*   Create an embedding of the metadata 512 -> 256 \n",
        "*   Combine all embeddings for movie tf-idf vectors, user and ratings to arrive at a common embedding space (256 sized embeddings per entity)\n",
        "*   Use the embeddings to train the model and get predictions on the test data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw7fwxvQc4DV"
      },
      "source": [
        "### Additional Hints:\n",
        "\n",
        "Dense layer setup :\n",
        "[Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense#example_2)\n",
        "\n",
        "Create model using tf.keras API : \n",
        "[Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model#used-in-the-notebooks)\n",
        "\n",
        "Compile model using : [Compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
        "\n",
        "Fit model : \n",
        "[fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
        "\n",
        "Predict accuracy: [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hINM6pCk3yKz"
      },
      "source": [
        "### Q8.3: Building a Deep Learning Hybrid Recommendation System\n",
        "\n",
        "We will be building the following hybrid deep learning recommendation model as scene in the following schematic.\n",
        "\n",
        "![](./images/hybrid-dl-model.png)\n",
        "\n",
        "__Your Turn:__ Fill in the necessary blank code snippets in the following sections to train your own DL hybrid recommendation system\n",
        "\n",
        "#### Create Configuration Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmOFI6gNZOYy"
      },
      "source": [
        "# ceate a copy of the filtered data frame\n",
        "df_filtered_cp = df_filtered.copy(deep=True)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eknbQW6mHsKN"
      },
      "source": [
        "# Create user- & movie-id mapping\n",
        "user_id_mapping = {id:i for i, id in enumerate(df_filtered_cp['User'].unique())}\n",
        "movie_id_mapping = {id:i for i, id in enumerate(df_filtered_cp['Movie'].unique())}"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLHTi2NsIEAM"
      },
      "source": [
        "# use dataframe map function to map users & movies to mapped ids based on above mapping\n",
        "df_filtered_cp['User'] = df_filtered_cp['User'].map(user_id_mapping)\n",
        "df_filtered_cp['Movie'] = df_filtered_cp['Movie'].map(movie_id_mapping)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh1Bg5Q_38mF"
      },
      "source": [
        "#### Create Movie Description Dataset (Content)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoAHPk1SIECT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "5500a94c-43df-40f9-99ed-833083f0502d"
      },
      "source": [
        "# Preprocess metadata\n",
        "tmp_metadata = movie_metadata.copy()\n",
        "tmp_metadata.index = tmp_metadata.index.str.lower()\n",
        "\n",
        "# Preprocess titles\n",
        "tmp_titles = movie_titles.drop('Year', axis=1).copy()\n",
        "tmp_titles = tmp_titles.reset_index().set_index('Name')\n",
        "tmp_titles.index = tmp_titles.index.str.lower()\n",
        "\n",
        "# Combine titles and metadata\n",
        "df_id_descriptions = tmp_titles.join(tmp_metadata).dropna().set_index('Id')\n",
        "df_id_descriptions['overview'] = df_id_descriptions['overview'].str.lower()\n",
        "#del tmp_metadata,tmp_titles\n",
        "print('Movie Description DF Shape:', df_id_descriptions.shape)\n",
        "df_id_descriptions.tail()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie Description DF Shape: (6939, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16182</th>\n",
              "      <td>daryl zero is a private investigator. along wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15233</th>\n",
              "      <td>clear the runway for derek zoolander, vh1's th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>a newly arrived governor finds his province un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17631</th>\n",
              "      <td>in 1879, during the zulu wars, man of the peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17631</th>\n",
              "      <td>as a child, ali neuman narrowly escaped being ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                overview\n",
              "Id                                                      \n",
              "16182  daryl zero is a private investigator. along wi...\n",
              "15233  clear the runway for derek zoolander, vh1's th...\n",
              "1210   a newly arrived governor finds his province un...\n",
              "17631  in 1879, during the zulu wars, man of the peop...\n",
              "17631  as a child, ali neuman narrowly escaped being ..."
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7__gU8E44m-"
      },
      "source": [
        "#### Create User-Rating Filtered Dataset (Collaborative)\n",
        "\n",
        "Here we filter out movie-user-ratings where movies don't have descriptions (content)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-NM3bV_JOG_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b0645d59-9792-40ad-d00d-3878a130b529"
      },
      "source": [
        "df_hybrid = (df_filtered_cp.set_index('Movie')\n",
        "               .join(df_id_descriptions)\n",
        "               .dropna()\n",
        "               .drop('overview', axis=1)\n",
        "               .reset_index().rename({'index':'Movie'}, \n",
        "                                      axis=1))\n",
        "print('Movie-User-Rating DF Shape:', df_hybrid.shape)\n",
        "df_hybrid.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie-User-Rating DF Shape: (2315356, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie</th>\n",
              "      <th>User</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>367</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>397</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>942</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>807</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Movie  User  Rating\n",
              "0     12    12     3.0\n",
              "1     12   367     5.0\n",
              "2     12   397     3.0\n",
              "3     12   942     3.0\n",
              "4     12   807     4.0"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7CHcKM_JOOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be95457-3a9a-4952-cb99-48b2f0a6a50d"
      },
      "source": [
        "# Split train- & testset\n",
        "n = 300000\n",
        "df_hybrid = df_hybrid.sample(frac=1).reset_index(drop=True)\n",
        "df_hybrid_train = df_hybrid[:-n]\n",
        "df_hybrid_test = df_hybrid[-n:]\n",
        "df_hybrid_train.shape, df_hybrid_test.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2015356, 3), (300000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k33OwrFO5RpF"
      },
      "source": [
        "#### Generate TFIDF Vectors for Train and Test Datasets (Movie Descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqiyhdelU775"
      },
      "source": [
        "# Create tf-idf matrix for movie description vectors - HINT: check the overview column of df_id_description\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_hybrid = tfidf.fit_transform(df_id_descriptions['overview'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgxZz-0wU7-C"
      },
      "source": [
        "# Get mapping from movie-ids to indices in tfidf-matrix\n",
        "movie_idx_mapping = {id:i for i, id in enumerate(df_id_descriptions.index)}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HemfBsDqU8AL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6149961f-e710-434f-a3cb-a38a65145dbb"
      },
      "source": [
        "# get train data tfidf vectors\n",
        "train_tfidf = []\n",
        "\n",
        "# Iterate over all movie-ids and save the tfidf-vectors (sparse format for memory efficiency)\n",
        "for idx in tqdm(df_hybrid_train['Movie'].values):\n",
        "    index = movie_idx_mapping[idx]\n",
        "    train_tfidf.append(tfidf_hybrid[index])\n",
        "\n",
        "len(train_tfidf)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2015356/2015356 [03:34<00:00, 9416.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2015356"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AqgNsqrU8CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8b2ae3-d3c6-4076-9a2c-66ae1c98fe5e"
      },
      "source": [
        "# get test data tfidf vectors\n",
        "test_tfidf = []\n",
        "\n",
        "# Iterate over all movie-ids and save the tfidf-vectors (sparse format for memory efficiency)\n",
        "for idx in tqdm(df_hybrid_test['Movie'].values):\n",
        "    index = movie_idx_mapping[idx]\n",
        "    test_tfidf.append(tfidf_hybrid[index])\n",
        "\n",
        "len(test_tfidf)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300000/300000 [00:32<00:00, 9333.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300000"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dyKQnCNdQTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baefe902-1456-4be4-e320-66997102e5cc"
      },
      "source": [
        "# Stack the sparse matrices\n",
        "train_tfidf = vstack(train_tfidf)\n",
        "test_tfidf = vstack(test_tfidf)\n",
        "\n",
        "train_tfidf.shape, test_tfidf.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2015356, 24144), (300000, 24144))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMI3SxfNdwNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dbffa0-b3e2-4857-e013-f2272e3e9c5f"
      },
      "source": [
        "type(train_tfidf)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4m5y7Zv5ZuK"
      },
      "source": [
        "This shows we are using sparse matrices to represent the vectors as dense vectors would typically give a out of memory error!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCZjFT6JeIDs"
      },
      "source": [
        "#### Construct Deep Learning Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_WYqzMpeJby"
      },
      "source": [
        "# setup NN parameters\n",
        "user_embed_dim = 256\n",
        "movie_embed_dim = 256\n",
        "userid_input_shape = 1\n",
        "movieid_input_shape = 1\n",
        "tfidf_input_shape = tfidf_hybrid.shape[1]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea74tynzeqGB"
      },
      "source": [
        "# Create the input layers\n",
        "\n",
        "# user and movie input layers\n",
        "user_id_input = Input(shape=(userid_input_shape,), name='user')\n",
        "movie_id_input = Input(shape=(movieid_input_shape,), name='movie')\n",
        "\n",
        "# tfidf input layer\n",
        "tfidf_input = Input(shape=(tfidf_input_shape,), name='tfidf', sparse=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc_bGQ6ne3Cj"
      },
      "source": [
        "# Create embeddings layers for users and movies\n",
        "\n",
        "# user embedding\n",
        "user_embedding = Embedding(output_dim=user_embed_dim,\n",
        "                           input_dim=len(user_id_mapping),\n",
        "                           input_length=userid_input_shape,\n",
        "                           name='user_embedding')(user_id_input)\n",
        "\n",
        "# movie embedding\n",
        "movie_embedding = Embedding(output_dim=movie_embed_dim,\n",
        "                           input_dim=len(movie_id_mapping),\n",
        "                           input_length=movieid_input_shape,\n",
        "                           name='movie_embedding')(movie_id_input)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm_H8CaXe3Gn"
      },
      "source": [
        "# Dimensionality reduction with Dense layers\n",
        "tfidf_vectors = Dense(512, activation='relu')(tfidf_input)\n",
        "tfidf_vectors = Dense(256, activation='relu')(tfidf_vectors)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlNBswdYe3I8"
      },
      "source": [
        "# Reshape both user and movie embedding layers\n",
        "user_vectors = Reshape([user_embed_dim])(user_embedding)\n",
        "movie_vectors = Reshape([movie_embed_dim])(movie_embedding)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfcefQQEe3E2"
      },
      "source": [
        "# Concatenate all layers into one \n",
        "hybrid_layer = Concatenate()([user_vectors, movie_vectors, tfidf_vectors])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfZK5Dg9oxVA"
      },
      "source": [
        "# add in dense and output layers\n",
        "dense = Dense(512, activation='relu')(hybrid_layer)\n",
        "dense = Dropout(0.2)(dense)\n",
        "output = Dense(1)(dense)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLeDjgzoxYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcb3359-0c3c-4129-fba9-21f6abe6f340"
      },
      "source": [
        "# create and view model summary\n",
        "model = Model(inputs=[user_id_input, movie_id_input, tfidf_input], outputs=output)\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "movie (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tfidf (InputLayer)              [(None, 24144)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 256)       5331968     user[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "movie_embedding (Embedding)     (None, 1, 256)       445696      movie[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          12362240    tfidf[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 256)          0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 256)          0           movie_embedding[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 768)          0           reshape_2[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          393728      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            513         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 18,665,473\n",
            "Trainable params: 18,665,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upDnm3r76Ivj"
      },
      "source": [
        "#### Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmzWu6Xhoxnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9308981a-2c70-44fc-9b1f-e5ed325389d1"
      },
      "source": [
        "# Build ustom training loop since TensorFlow doesn't allow batch training for sparse Input\n",
        "batch_size=1024\n",
        "epochs=1\n",
        "optimizer = Adam()\n",
        "X = [df_hybrid_train['User'], df_hybrid_train['Movie'], train_tfidf]\n",
        "y = df_hybrid_train['Rating']\n",
        "n_batch = y.shape[0]//batch_size+1\n",
        "idx = np.arange(0, y.shape[0], batch_size)\n",
        "idx = np.concatenate((idx, [y.shape[0]]))\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_hat = model(x, training=True)\n",
        "        loss_value = MSE(y, y_hat)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss_value\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for i in range(0, n_batch):\n",
        "        start_idx = idx[i]\n",
        "        end_idx = idx[i+1]\n",
        "        x_batch_train = [X[0][start_idx:end_idx], X[1][start_idx:end_idx], np.array(X[2][start_idx:end_idx].todense())]\n",
        "        y_batch_train = y[start_idx:end_idx]\n",
        "\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "        if i % 100 == 0:\n",
        "            print('Step: '+str(i))\n",
        "            print('Training loss: %.2f'%float(np.nanmean(loss_value)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Step: 0\n",
            "Training loss: 13.45\n",
            "Step: 100\n",
            "Training loss: 1.16\n",
            "Step: 200\n",
            "Training loss: 1.23\n",
            "Step: 300\n",
            "Training loss: 1.17\n",
            "Step: 400\n",
            "Training loss: 1.23\n",
            "Step: 500\n",
            "Training loss: 1.23\n",
            "Step: 600\n",
            "Training loss: 1.19\n",
            "Step: 700\n",
            "Training loss: 1.24\n",
            "Step: 800\n",
            "Training loss: 1.20\n",
            "Step: 900\n",
            "Training loss: 1.16\n",
            "Step: 1000\n",
            "Training loss: 1.25\n",
            "Step: 1100\n",
            "Training loss: 1.19\n",
            "Step: 1200\n",
            "Training loss: 1.17\n",
            "Step: 1300\n",
            "Training loss: 1.16\n",
            "Step: 1400\n",
            "Training loss: 1.12\n",
            "Step: 1500\n",
            "Training loss: 1.18\n",
            "Step: 1600\n",
            "Training loss: 1.14\n",
            "Step: 1700\n",
            "Training loss: 1.20\n",
            "Step: 1800\n",
            "Training loss: 1.16\n",
            "Step: 1900\n",
            "Training loss: 1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLkTXmxhpK7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63522b92-d793-4796-e2c7-66041bd1311e"
      },
      "source": [
        "# create test input data and true outputs\n",
        "X_test = [df_hybrid_test['User'][:100], df_hybrid_test['Movie'][:100], np.array(test_tfidf[:100].todense())]\n",
        "y_true = df_hybrid_test['Rating'].values[:100]\n",
        "\n",
        "# Test model by making predictions on test data\n",
        "y_pred = model.predict(X_test).ravel()\n",
        "# clip upper and lower ratings\n",
        "y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
        "\n",
        "#  Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
        "print('\\n\\nTesting Result With DL Hybrid Recommender: {:.4f} RMSE'.format(rmse))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Testing Result With DL Hybrid Recommender: 1.1423 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecgDG4C9pLAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "bf3977b4-de1c-49de-a675-32e87d2de2e2"
      },
      "source": [
        "## Let's see how our collaborative model performs by seeing the predicted and actual rating for the given user and movie pair\n",
        "results_df = pd.DataFrame({\n",
        "    'User ID': df_hybrid_test['User'].values[:100],\n",
        "    'Movie ID': df_hybrid_test['Movie'].values[:100],\n",
        "    'Movie Name': [movie_titles['Name'].iloc[item] for item in df_hybrid_test['Movie']][:100],\n",
        "    'Predicted Rating': np.round(y_pred, 1),\n",
        "    'Actual Rating': y_true[:100]\n",
        "})\n",
        "\n",
        "results_df.head(20)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Movie ID</th>\n",
              "      <th>Movie Name</th>\n",
              "      <th>Predicted Rating</th>\n",
              "      <th>Actual Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1452</td>\n",
              "      <td>1605</td>\n",
              "      <td>Til There Was You</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6514</td>\n",
              "      <td>630</td>\n",
              "      <td>Unleashed</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9200</td>\n",
              "      <td>45</td>\n",
              "      <td>Rudolph the Red-Nosed Reindeer</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9201</td>\n",
              "      <td>1260</td>\n",
              "      <td>Mojados: Through the Night</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19098</td>\n",
              "      <td>501</td>\n",
              "      <td>Mitch Hedberg: Mitch All Together</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>16045</td>\n",
              "      <td>760</td>\n",
              "      <td>O Fantasma</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15260</td>\n",
              "      <td>1530</td>\n",
              "      <td>The Crucible</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15962</td>\n",
              "      <td>1114</td>\n",
              "      <td>Hammers Over the Anvil</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5932</td>\n",
              "      <td>344</td>\n",
              "      <td>Star Trek: Voyager: Season 5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5212</td>\n",
              "      <td>351</td>\n",
              "      <td>Pick a Card</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>16958</td>\n",
              "      <td>486</td>\n",
              "      <td>Doctor Who: Lost in Time: The Patrick Troughto...</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>17220</td>\n",
              "      <td>763</td>\n",
              "      <td>Scarface: 20th Anniversary Edition: Bonus Mate...</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15130</td>\n",
              "      <td>172</td>\n",
              "      <td>The Devil's Brigade</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13991</td>\n",
              "      <td>83</td>\n",
              "      <td>The Powerpuff Girls Movie</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10062</td>\n",
              "      <td>148</td>\n",
              "      <td>The Edward R. Murrow Collection</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>13507</td>\n",
              "      <td>113</td>\n",
              "      <td>Dominion Tank Police Part 1 &amp; 2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6910</td>\n",
              "      <td>711</td>\n",
              "      <td>Homicide: Life on the Street: Season 7</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18932</td>\n",
              "      <td>1470</td>\n",
              "      <td>Voices of Iraq</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5054</td>\n",
              "      <td>127</td>\n",
              "      <td>Mr. Vampire</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>14196</td>\n",
              "      <td>1272</td>\n",
              "      <td>The Thrill Seekers</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Movie ID  ... Predicted Rating  Actual Rating\n",
              "0      1452      1605  ...              3.5            3.0\n",
              "1      6514       630  ...              3.5            2.0\n",
              "2      9200        45  ...              3.5            4.0\n",
              "3      9201      1260  ...              3.5            5.0\n",
              "4     19098       501  ...              3.5            3.0\n",
              "5     16045       760  ...              3.5            4.0\n",
              "6     15260      1530  ...              3.5            5.0\n",
              "7     15962      1114  ...              3.5            4.0\n",
              "8      5932       344  ...              3.5            4.0\n",
              "9      5212       351  ...              3.6            4.0\n",
              "10    16958       486  ...              3.6            4.0\n",
              "11    17220       763  ...              3.6            2.0\n",
              "12    15130       172  ...              3.5            4.0\n",
              "13    13991        83  ...              3.6            4.0\n",
              "14    10062       148  ...              3.5            5.0\n",
              "15    13507       113  ...              3.5            3.0\n",
              "16     6910       711  ...              3.6            3.0\n",
              "17    18932      1470  ...              3.7            3.0\n",
              "18     5054       127  ...              3.5            4.0\n",
              "19    14196      1272  ...              3.3            3.0\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ]
}